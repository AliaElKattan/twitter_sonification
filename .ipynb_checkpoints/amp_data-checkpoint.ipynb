{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading & Cleaning Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets.csv', usecols = ['timestamp', 'text'],encoding='latin1')  #nrows 'in_reply_to_status_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliae\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\aliae\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#Add cols for month and year\n",
    "\n",
    "index = 0;\n",
    "\n",
    "tweets['month'] = 0\n",
    "tweets['year'] = 0\n",
    "\n",
    "for i in tweets['timestamp']:\n",
    "    tweets['year'][index]=tweets['timestamp'][index][0:4]\n",
    "    tweets['month'][index]=tweets['timestamp'][index][5:7]\n",
    "    index+=1\n",
    "\n",
    "#Delete timestamp column\n",
    "del tweets['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lowercase\n",
    "tweets['text'] = tweets['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up - remove replies, retweets\n",
    "\n",
    "tweets = tweets[~tweets.text.str.contains(\"@\")]\n",
    "tweets = tweets[~tweets.text.str.contains(\"rt\")]\n",
    "#tweets = tweets[~tweets.text.str.contains(\"plx11zpn21\")]\n",
    "\n",
    "#Remove all non-letter or number chars\n",
    "tweets['text'] = tweets['text'].replace('[^a-zA-Z0-9]',' ', regex = True) #replace non letters or numbers\n",
    "\n",
    "#Split data by year (2011 - 2014) & sort months in descending order\n",
    "def tweets_by_year(year):\n",
    "    is_year = tweets['year'] == year\n",
    "    return tweets[is_year].sort_values(by=['month'])\n",
    "\n",
    "tweets_2011 = tweets_by_year(2011)\n",
    "tweets_2012 = tweets_by_year(2012)\n",
    "tweets_2013 = tweets_by_year(2013)\n",
    "tweets_2014 = tweets_by_year(2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''wordcloud = WordCloud(\n",
    "    width = 3000,\n",
    "    height = 2000,\n",
    "    background_color = 'white',\n",
    "    stopwords = STOPWORDS\n",
    ").generate(str(tweets_x)\n",
    ")\n",
    "fig = plt.figure(\n",
    "    figsize = (40, 30),\n",
    "    facecolor = 'k',\n",
    "    edgecolor = 'k')\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  month  year\n",
      "9576                                         masr  lt 3      2  2011\n",
      "9569                             school spirit     lt 3      3  2011\n",
      "9565                      grade seven  school spirit         3  2011\n",
      "9559          walk for nile was such a succesful event       5  2011\n",
      "9556                                                ...      5  2011\n",
      "...                                                 ...    ...   ...\n",
      "2725                last minute goal by  sanchez   coyg     12  2014\n",
      "2729           lowkey   special  http   t co avzagjkg6p     12  2014\n",
      "2732  how can people be pro  sisi  but against  muba...     12  2014\n",
      "2716                                                ...     12  2014\n",
      "2698  confessions of an economic hitman   a book tha...     12  2014\n",
      "\n",
      "[1800 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Combine sorted 4 years into 1 dataset\n",
    "\n",
    "tweets_4yrs = pd.concat([tweets_2011, tweets_2012, tweets_2013, tweets_2014])\n",
    "print(tweets_4yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tweets_2013_s)\n",
    "\n",
    "def df_to_text(tweets):\n",
    "    return tweets.text.str.cat(sep=' ')\n",
    "\n",
    "def tweets_by_month(year):\n",
    "    is_year = tweets['year'] == year\n",
    "    return tweets[is_year].sort_values(by=['month'])\n",
    "\n",
    "#for i in tweets['text']:\n",
    "#alltweets = alltweets + ' ' + tweets['text'][index]\n",
    " ## index+=1\n",
    "\n",
    "#stop_words = frozenset(STOPWORDS)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "split_it = tweets_2011_t.split() \n",
    "Counter = Counter(split_it) \n",
    "#print(Counter.most_common(100))\n",
    "\n",
    "\n",
    "#tweets_4yrs.to_csv(r'tweets_4years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2011 = tweets_2011.reset_index()\n",
    "del tweets_2011['index']\n",
    "\n",
    "tweets_2012 = tweets_2012.reset_index()\n",
    "del tweets_2012['index']\n",
    "\n",
    "tweets_2013 = tweets_2013.reset_index()\n",
    "del tweets_2013['index']\n",
    "\n",
    "tweets_2014 = tweets_2014.reset_index()\n",
    "del tweets_2014['index']tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year month count                                               text  \\\n",
      "0   2011     2     1                                         masr  lt 3   \n",
      "1   2011     3     2  school spirit     lt 3; grade seven  school sp...   \n",
      "2   2011     5     8  walk for nile was such a succesful event ;    ...   \n",
      "3   2011     6    53  ahly fo2 el gamee3   ;  ineedtostop delaying t...   \n",
      "4   2011     7    50  hamza namira   lt 3;  nowplaying   ew3edoony  ...   \n",
      "5   2011     8    48   protectgaza  protectgaza  protectgaza  protec...   \n",
      "6   2011     9    50  leih law 2olt ra2yak teb2a 5alas erhaaby   zap...   \n",
      "7   2011    10    13  r i p steve jobs  great succesful person ; tab...   \n",
      "8   2011    11    21   tomorrowisdecember trending    oh really  i d...   \n",
      "9   2011    12    49  talent show   d; bored  ; so i open a webpage ...   \n",
      "10   NaN   NaN   NaN                                                NaN   \n",
      "11   NaN   NaN   NaN                                                NaN   \n",
      "0   2012     1    22  i ll spend the first three months writing  201...   \n",
      "1   2012     2    20  my hannnddd    ; ya el midan ; matloob za3eeem...   \n",
      "2   2012     3    67  you ll be asked   what did you do for your bro...   \n",
      "3   2012     4    33  what s happening with barcelona ; esm el ahly ...   \n",
      "4   2012     5    80  nemt 4 sa3at w daya3t 3alaya el yom   ;       ...   \n",
      "5   2012     6   106   turkishdirectionersareproudofzaynsreligion is...   \n",
      "6   2012     7    44  http   t co avpdpcxe; mostafa bakry etbaaaaahh...   \n",
      "7   2012     8    87   never give up  i will never just quit  i will...   \n",
      "8   2012     9    31  http   t co 2wophg2s must respect  avaaz; http...   \n",
      "9   2012    10    88  every time i see  district 3  trending i remem...   \n",
      "10  2012    11   144  https   t co pjkpu4in                         ...   \n",
      "11  2012    12    56                                          ;     ...   \n",
      "0   2013     1    67  don t ever say you re on your way down    when...   \n",
      "1   2013     2    43  happy valentine s day  ento nas cute 5alis ; m...   \n",
      "2   2013     3    50  last year hayah was 12th place   it ll be bett...   \n",
      "3   2013     4    23  http   t co fdeml4natm vote for  e zee ramp ; ...   \n",
      "4   2013     5    22  women s champions league final   ta32eed  lyon...   \n",
      "5   2013     6    24  during a time when lies spread  and people cla...   \n",
      "6   2013     7    69  badei isn t in jail  he s talking on jazira fr...   \n",
      "7   2013     8    35                                                ...   \n",
      "8   2013     9    23                                                ...   \n",
      "9   2013    10    68  bbm pin   7c8b70de  bbm is now officially avai...   \n",
      "10  2013    11    57  it s the day of the doctor    savetheday; http...   \n",
      "11  2013    12    31   books  best weapons in the world    arm yours...   \n",
      "0   2014     1    60  abandoning timelines and newsfeed till i watch...   \n",
      "1   2014     2    36  hahaha  flappy bird deleted off app store  and...   \n",
      "2   2014     3     7  everything is awesome   thelegomovie; the rule...   \n",
      "3   2014     4    20  won again   75 point difference   hiabotball20...   \n",
      "4   2014     5     9  leave a light  a light on   midnight; brillian...   \n",
      "5   2014     6    11  massive respect to the algerians for such a pe...   \n",
      "6   2014     7    11   this is not a war  it is systematic genocide ...   \n",
      "7   2014     8     5  what i want to be doing for the rest of my lif...   \n",
      "8   2014    10     7  i m actually pretty excited about windows 10  ...   \n",
      "9   2014    11    27  rise and fall; was 2 mins away from where i li...   \n",
      "10  2014    12    21  4 1 what a penalty hahaha  cazorla  coyg; matt...   \n",
      "11   NaN   NaN   NaN                                                NaN   \n",
      "\n",
      "                                         common_words  \n",
      "0                        {'masr': 4, 'lt': 1, '3': 1}  \n",
      "1   {'school': 18, 'spirit': 18, 'lt': 1, '3;': 1,...  \n",
      "2   {'walk': 49, 'for': 1, 'nile': 49, 'was': 2, '...  \n",
      "3   {'ahly': 3003, 'fo2': 1, 'el': 7, 'gamee3': 42...  \n",
      "4   {'hamza': 265, 'namira': 265, 'lt': 7, '3;': 6...  \n",
      "5   {'protectgaza': 3200, ';': 36, 'erfa3': 320, '...  \n",
      "6   {'leih': 432, 'law': 1, '2olt': 432, 'ra2yak':...  \n",
      "7   {'r': 1, 'i': 2, 'p': 1, 'steve': 210, 'jobs':...  \n",
      "8   {'tomorrowisdecember': 165, 'trending': 330, '...  \n",
      "9                                                 NaN  \n",
      "10                                                NaN  \n",
      "11                                                NaN  \n",
      "0   {'i': 2, 'll': 1, 'spend': 192, 'the': 3, 'fir...  \n",
      "1   {'my': 1, 'hannnddd': 144, ';': 13, 'ya': 4, '...  \n",
      "2   {'you': 9, 'll': 2, 'be': 8, 'asked': 608, 'wh...  \n",
      "3   {'what': 1, 's': 1, 'happening': 279, 'with': ...  \n",
      "4   {'nemt': 751, '4': 2, 'sa3at': 751, 'w': 7, 'd...  \n",
      "5   {'turkishdirectionersareproudofzaynsreligion':...  \n",
      "6   {'http': 2, 't': 6, 'co': 2, 'avpdpcxe;': 337,...  \n",
      "7   {'never': 3592, 'give': 1796, 'up': 3, 'i': 15...  \n",
      "8   {'http': 8, 't': 13, 'co': 8, '2wophg2s': 351,...  \n",
      "9   {'every': 1734, 'time': 1734, 'i': 16, 'see': ...  \n",
      "10  {'https': 1250, 't': 28, 'co': 15, 'pjkpu4in':...  \n",
      "11                                                NaN  \n",
      "0   {'don': 4, 't': 15, 'ever': 1, 'say': 2, 'you'...  \n",
      "1   {'happy': 358, 'valentine': 358, 's': 7, 'day'...  \n",
      "2   {'last': 2208, 'year': 1656, 'hayah': 552, 'wa...  \n",
      "3   {'http': 4, 't': 9, 'co': 4, 'fdeml4natm': 299...  \n",
      "4   {'women': 278, 's': 5, 'champions': 278, 'leag...  \n",
      "5   {'during': 1, 'a': 3, 'time': 604, 'when': 1, ...  \n",
      "6   {'badei': 597, 'isn': 2, 't': 23, 'in': 4, 'ja...  \n",
      "7   {';': 15, 'aqua': 351, 'park;': 351, 'can': 6,...  \n",
      "8   {';': 11, 'honestly': 294, 'ios': 1, '7': 1, '...  \n",
      "9   {'bbm': 2, 'pin': 1, '7c8b70de': 711, 'is': 9,...  \n",
      "10  {'it': 2, 's': 7, 'the': 20, 'day': 1, 'of': 8...  \n",
      "11                                                NaN  \n",
      "0   {'abandoning': 749, 'timelines': 749, 'and': 1...  \n",
      "1   {'hahaha': 472, 'flappy': 472, 'bird': 472, 'd...  \n",
      "2   {'everything': 64, 'is': 1, 'awesome': 64, 'th...  \n",
      "3   {'won': 4, 'again': 1, '75': 1, 'point': 296, ...  \n",
      "4   {'leave': 88, 'a': 3, 'light': 176, 'on': 1, '...  \n",
      "5   {'massive': 109, 'respect': 109, 'to': 2, 'the...  \n",
      "6   {'this': 1, 'is': 2, 'not': 1, 'a': 6, 'war': ...  \n",
      "7   {'what': 1, 'i': 4, 'want': 66, 'to': 2, 'be':...  \n",
      "8   {'i': 4, 'm': 2, 'actually': 83, 'pretty': 83,...  \n",
      "9   {'rise': 371, 'and': 4, 'fall;': 371, 'was': 2...  \n",
      "10                                                NaN  \n",
      "11                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "#by_month_2011 = pd.DataFrame(columns=['year', 'month', 'count','text' ]) #, 'common_words', 'themes'\n",
    "from collections import Counter\n",
    "\n",
    "def tweets_by_month(tweets_year):\n",
    "    #tweets_year=tweets_year.reset_index()\n",
    "    #del tweets_year['index']\n",
    "    stop_words = STOPWORDS\n",
    "    num_rows = len(tweets_year.index)\n",
    "    by_month = pd.DataFrame(index=np.arange(12), columns=['year', 'month', 'count','text','common_words'])\n",
    "    \n",
    "    by_month['month'][0]=tweets_year['month'][0]\n",
    "    by_month['year'][0] = tweets_year['year'][0] \n",
    "    by_month['text'][0] = tweets_year['text'][0]\n",
    "    by_month['count'][0] = 1\n",
    "    \n",
    "    ind_m = 0 \n",
    "    ind_y = 1\n",
    "    #range(num_rows)\n",
    "    for i in range(num_rows-1):\n",
    "        if tweets_year['month'][ind_y] > by_month['month'][ind_m]: #initialize new month\n",
    "            split_it = by_month['text'][ind_m].split() \n",
    "            count = Counter(split_it) \n",
    "            for i in split_it:\n",
    "                words = [w for w in split_it if w not in STOPWORDS and len(w) > 3]\n",
    "                count.update(words)\n",
    "            by_month['common_words'][ind_m]=count\n",
    "            \n",
    "            ind_m+=1\n",
    "            by_month['month'][ind_m] = tweets_year['month'][ind_y]\n",
    "            by_month['year'][ind_m] = tweets_year['year'][ind_y] \n",
    "            by_month['text'][ind_m] = tweets_year['text'][ind_y]\n",
    "            by_month['count'][ind_m]=1\n",
    "        else:\n",
    "            #print(\"FALSE\")\n",
    "            by_month['count'][ind_m]+=1\n",
    "            by_month['text'][ind_m]= by_month['text'][ind_m] + '; ' + tweets_year['text'][ind_y]\n",
    "        ind_y = ind_y +1\n",
    "    \n",
    "    return by_month\n",
    "    \n",
    "by_month_2011 = tweets_by_month(tweets_2011)\n",
    "by_month_2012 = tweets_by_month(tweets_2012)\n",
    "by_month_2013 = tweets_by_month(tweets_2013)\n",
    "by_month_2014 = tweets_by_month(tweets_2014)\n",
    "\n",
    "tweets_by_month = pd.concat([by_month_2011, by_month_2012, by_month_2013, by_month_2014])\n",
    "print(tweets_by_month)\n",
    "\n",
    "tweets_by_month.to_csv(r'tweets_by_month.csv')\n",
    "\n",
    "#tweets_2011 = tweets_2011.reset_index()\n",
    "\n",
    "#print(tweets_2011['month'][24])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  month  year\n",
      "9576                                         masr  lt 3      2  2011\n",
      "9569                             school spirit     lt 3      3  2011\n",
      "9565                      grade seven  school spirit         3  2011\n",
      "9559          walk for nile was such a succesful event       5  2011\n",
      "9556                                                ...      5  2011\n",
      "...                                                 ...    ...   ...\n",
      "8641        heal the world  make it a better place   mj     12  2011\n",
      "8640            shewayet baltageya afalo el midan tany      12  2011\n",
      "8638                                                        12  2011\n",
      "8659                           mohamed beltagy  y   fjp     12  2011\n",
      "8515              why isn t egypt a  trendlocation          12  2011\n",
      "\n",
      "[295 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tweets_2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('syria', 381553),\n",
       " ('lowkey', 206944),\n",
       " ('tahrir', 200477),\n",
       " ('world', 174609),\n",
       " ('will', 155208),\n",
       " ('people', 135807),\n",
       " ('palestine', 129340),\n",
       " ('trending', 129340),\n",
       " ('never', 116406),\n",
       " ('mesh', 97005),\n",
       " ('3ashan', 97005),\n",
       " ('maherzain', 90538),\n",
       " ('ahly', 84071),\n",
       " ('free', 77604),\n",
       " ('ba2a', 77604),\n",
       " ('lehhayah', 71137),\n",
       " ('know', 71137),\n",
       " ('change', 71137),\n",
       " ('terrorist', 71137),\n",
       " ('shafik', 71137)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = STOPWORDS\n",
    "split_2011 = tweets_2011_t.split()\n",
    "split_2012 = tweets_2012_t.split()\n",
    "split_2013= tweets_2013_t.split()\n",
    "split_2014= tweets_2014_t.split()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def mostCommonWords(text):\n",
    "    finalCount = Counter(text)\n",
    "    for i in text:\n",
    "        words = [w for w in text if w not in stop_words and len(w) > 3]\n",
    "        finalCount.update(words)  # update final count using the words list\n",
    "    return finalCount\n",
    "\n",
    "#mostCommonWords(split_2011).most_common(20)\n",
    "mostCommonWords(split_2012).most_common(20)\n",
    "#mostCommonWords(split_2013).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  month  year\n",
      "9576                                         masr  lt 3      2  2011\n",
      "9569                             school spirit     lt 3      3  2011\n",
      "9565                      grade seven  school spirit         3  2011\n",
      "9559          walk for nile was such a succesful event       5  2011\n",
      "9556                                                ...      5  2011\n",
      "...                                                 ...    ...   ...\n",
      "2725                last minute goal by  sanchez   coyg     12  2014\n",
      "2729           lowkey   special  http   t co avzagjkg6p     12  2014\n",
      "2732  how can people be pro  sisi  but against  muba...     12  2014\n",
      "2716                                                ...     12  2014\n",
      "2698  confessions of an economic hitman   a book tha...     12  2014\n",
      "\n",
      "[1799 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tweets_4yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = pd.read_csv('tweets_by_volume.csv', encoding='latin1')  #nrows 'in_reply_to_status_id'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "volume2 = pd.DataFrame(index=np.arange(1799), columns=['index', 'pitch', 'channels'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  month  count  volume  pitch\n",
      "0   2011      2      1       1      6\n",
      "1   2011      3      2       1      5\n",
      "2   2011      4      0       0      0\n",
      "3   2011      5      8       1      5\n",
      "4   2011      6     53       3      6\n",
      "5   2011      7     50       2      5\n",
      "6   2011      8     48       2      7\n",
      "7   2011      9     50       2      8\n",
      "8   2011     10     13       1      1\n",
      "9   2011     11     21       1      2\n",
      "10  2011     12     49       2      4\n",
      "11  2012      1     22       1      6\n",
      "12  2012      2     20       1      2\n",
      "13  2012      3     67       3      2\n",
      "14  2012      4     33       2      3\n",
      "15  2012      5     80       4      5\n",
      "16  2012      6    106       4      6\n",
      "17  2012      7     44       2      4\n",
      "18  2012      8     87       4      6\n",
      "19  2012      9     31       2      5\n",
      "20  2012     10     88       4      4\n",
      "21  2012     11    144       4      3\n",
      "22  2012     12     56       3      5\n",
      "23  2013      1     67       3      6\n",
      "24  2013      2     43       2      6\n",
      "25  2013      3     50       2      5\n",
      "26  2013      4     23       1      6\n",
      "27  2013      5     22       1      6\n",
      "28  2013      6     24       1      3\n",
      "29  2013      7     69       3      2\n",
      "30  2013      8     35       2      1\n",
      "31  2013      9     23       1      1\n",
      "32  2013     10     68       3      1\n",
      "33  2013     11     57       2      4\n",
      "34  2013     12     31       2      5\n",
      "35  2014      1     60       3      3\n",
      "36  2014      2     36       2      4\n",
      "37  2014      3      7       1      5\n",
      "38  2014      4     20       1      6\n",
      "39  2014      5      9       1      3\n",
      "40  2014      6     11       1      2\n",
      "41  2014      7     11       1      1\n",
      "42  2014      8      5       1      4\n",
      "43  2014      9      0       0      0\n",
      "44  2014     10      7       1      5\n",
      "45  2014     11     27       2      3\n",
      "46  2014     12     21       1      2\n"
     ]
    }
   ],
   "source": [
    "print(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume2.to_csv(r'tweets_max.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def csv_to_text(volume3,label): \n",
    "    pitches = '1,'\n",
    "    \n",
    "    ind = 0\n",
    "    \n",
    "    for i in volume3[label]:\n",
    "        pitches = str(pitches) + str(' ') + str(volume3[label][ind])\n",
    "        ind+=1\n",
    "    pitches = pitches + ';'\n",
    "    return pitches\n",
    "    \n",
    "pitch_max = open(\"pitch_max.txt\", \"w\")\n",
    "n = pitch_max.write(csv_to_text(volume3,'pitch'))\n",
    "pitch_max.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pitch_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "channels_max = open(\"channels_max.txt\", \"w\")\n",
    "n = channels_max.write(csv_to_text('channels'))\n",
    "channels_max.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_max = open(\"index_max.txt\", \"w\")\n",
    "n = index_max.write(csv_to_text('index'))\n",
    "index_max.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pitch</th>\n",
       "      <th>channels</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>months_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>march</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>march</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>march</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>march</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>march</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>april</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>april</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>april</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>april</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>april</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>june</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>june</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>june</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>june</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>june</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>july</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>july</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>july</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>july</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>july</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>september</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>september</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>september</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>september</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>september</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index pitch channels  year month months_text\n",
       "0      1    60        1  2011     2    february\n",
       "1      1    60        1  2011     2    february\n",
       "2      1    62        1  2011     2    february\n",
       "3      1    69        1  2011     2    february\n",
       "4      1    60        1  2011     2    february\n",
       "5      2    52        1  2011     3       march\n",
       "6      2    59        1  2011     3       march\n",
       "7      2    52        1  2011     3       march\n",
       "8      2    52        1  2011     3       march\n",
       "9      2    57        1  2011     3       march\n",
       "10     3    78        0  2011     4       april\n",
       "11     3    75        0  2011     4       april\n",
       "12     3    78        0  2011     4       april\n",
       "13     3    78        0  2011     4       april\n",
       "14     3    75        0  2011     4       april\n",
       "15     4    57        1  2011     5         may\n",
       "16     4    52        1  2011     5         may\n",
       "17     4    57        1  2011     5         may\n",
       "18     4    57        1  2011     5         may\n",
       "19     4    52        1  2011     5         may\n",
       "20     5    60        3  2011     6        june\n",
       "21     5    60        3  2011     6        june\n",
       "22     5    62        3  2011     6        june\n",
       "23     5    69        3  2011     6        june\n",
       "24     5    69        3  2011     6        june\n",
       "25     6    52        2  2011     7        july\n",
       "26     6    57        2  2011     7        july\n",
       "27     6    59        2  2011     7        july\n",
       "28     6    57        2  2011     7        july\n",
       "29     6    59        2  2011     7        july\n",
       "30     7    72        2  2011     8      august\n",
       "31     7    69        2  2011     8      august\n",
       "32     7    72        2  2011     8      august\n",
       "33     7    69        2  2011     8      august\n",
       "34     7    69        2  2011     8      august\n",
       "35     8    78        2  2011     9   september\n",
       "36     8    75        2  2011     9   september\n",
       "37     8    78        2  2011     9   september\n",
       "38     8    75        2  2011     9   september\n",
       "39     8    75        2  2011     9   september"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "volume3 = pd.DataFrame(index=np.arange(370), columns=['index', 'pitch', 'channels'])\n",
    "\n",
    "\n",
    "vol1_index = 0\n",
    "vol3_index = 0\n",
    "\n",
    "'''\n",
    "for i in volume['count']:\n",
    "    for i in range(volume['volume'][vol1_index]):\n",
    "        volume3['index'][vol3_index] = vol1_index+1\n",
    "        volume3['pitch'][vol3_index] = volume['pitch'][vol1_index]\n",
    "        volume3['channels'][vol3_index] = volume['volume'][vol1_index]\n",
    "        vol3_index+=1\n",
    "    vol1_index+=1\n",
    "'''\n",
    "\n",
    "ch1 = [30,35]\n",
    "ch2 = [37,40]\n",
    "ch3 = [42,45]\n",
    "ch4 = [47,48,50]\n",
    "ch5 = [52,57,59]\n",
    "ch6 = [60,62,69]\n",
    "ch7 = [69,70,72]\n",
    "ch8 = [75,78]\n",
    "\n",
    "months = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "\n",
    "choices = [ch1,ch2,ch3,ch4,ch5,ch6,ch7,ch8]\n",
    "\n",
    "\n",
    "newdata = pd.DataFrame(index=np.arange(236), columns=['index', 'pitch', 'channels', 'year', 'month', 'months_text'])\n",
    "\n",
    "import random\n",
    "vol_index = 0\n",
    "index = 0\n",
    "\n",
    "for i in volume['count']:\n",
    "    for i in range(5):\n",
    "        newdata['index'][index] = vol_index+1\n",
    "        newdata['pitch'][index] = random.choice(choices[(volume['pitch'][vol_index])-1])\n",
    "        newdata['channels'][index] = volume['volume'][vol_index]\n",
    "        newdata['year'][index] = volume['year'][vol_index]\n",
    "        newdata['month'][index] = volume['month'][vol_index]\n",
    "        newdata['months_text'][index] = months[(newdata['month'][index])-1]\n",
    "        index+=1\n",
    "    vol_index+=1\n",
    "\n",
    "    \n",
    "    \n",
    "newdata.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pitches = open(\"new_pitches.txt\", \"w\")\n",
    "n = new_pitches.write(csv_to_text(newdata,'pitch'))\n",
    "new_pitches.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_year = open(\"new_year.txt\", \"w\")\n",
    "n = new_year.write(csv_to_text(newdata,'year'))\n",
    "new_year.close()\n",
    "\n",
    "new_month = open(\"new_month.txt\", \"w\")\n",
    "n = new_month.write(csv_to_text(newdata,'month'))\n",
    "new_month.close()\n",
    "\n",
    "new_month_text = open(\"new_month_text.txt\", \"w\")\n",
    "n = new_month_text.write(csv_to_text(newdata,'months_text'))\n",
    "new_month_text.close()\n",
    "\n",
    "new_channels = open(\"new_channels.txt\", \"w\")\n",
    "n = new_channels.write(csv_to_text(newdata,'channels'))\n",
    "new_channels.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5 6 6 6 6 6 7 7 7 7 7 8 8 8 8 8 9 9 9 9 9 10 10 10 10 10 11 11 11 11 11 12 12 12 12 12 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5 6 6 6 6 6 7 7 7 7 7 8 8 8 8 8 9 9 9 9 9 10 10 10 10 10 11 11 11 11 11 12 12 12 12 12 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5 6 6 6 6 6 7 7 7 7 7 8 8 8 8 8 9 9 9 9 9 10 10 10 10 10 11 11 11 11 11 12 12 12 12 12 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5 6 6 6 6 6 7 7 7 7 7 8 8 8 8 8 9 9 9 9 9 10 10 10 10 10 11 11 11 11 11 12 12 12 12 12 nan;\n"
     ]
    }
   ],
   "source": [
    "print(csv_to_text(newdata,'month'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index pitch channels\n",
      "0       1    60        4\n",
      "1       1    60        4\n",
      "2       1    69        4\n",
      "3       1    60        4\n",
      "4       1    69        4\n",
      "..    ...   ...      ...\n",
      "231    47    37        4\n",
      "232    47    37        4\n",
      "233    47    37        4\n",
      "234    47    37        4\n",
      "235   NaN   NaN      NaN\n",
      "\n",
      "[236 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 42FC-EFAD\n",
      "\n",
      " Directory of C:\\Users\\aliae\\Documents\n",
      "\n",
      "12/12/2019  01:07 PM    <DIR>          .\n",
      "12/12/2019  01:07 PM    <DIR>          ..\n",
      "12/12/2019  03:26 AM    <DIR>          .ipynb_checkpoints\n",
      "05/12/2019  10:26 PM             6,497 .RData\n",
      "12/06/2019  09:11 PM             4,414 .Rhistory\n",
      "09/22/2019  08:47 PM    <DIR>          1 NYUAD\n",
      "10/02/2019  07:01 PM    <DIR>          1InteractiveComputing\n",
      "06/19/2016  05:24 PM            97,424 2017 IAS JUNE 19 2016.docx\n",
      "11/21/2017  06:35 PM           199,964 activism poster 2.jpg\n",
      "11/27/2016  07:25 PM    <DIR>          Add-in Express\n",
      "01/31/2017  01:46 PM            65,599 Admission Ambassador - Timesheet (Alia).xlsx\n",
      "09/25/2016  05:43 PM    <DIR>          Adobe\n",
      "12/18/2017  02:23 AM            59,782 ahmad project cigarettes.wlmp\n",
      "12/18/2017  05:16 PM           214,381 Alia ElKattan - 4 year plan (2).pdf\n",
      "12/18/2017  05:14 PM            27,468 Alia ElKattan - 4 year plan.docx\n",
      "04/30/2017  03:17 PM            18,588 Alia ElKattan EfSI Reflections Jordan.docx\n",
      "04/08/2019  12:42 PM           409,702 AliaElKattan2018.pdf\n",
      "09/30/2016  05:10 PM           194,190 Alia's Meningitis Vaccination.jpeg\n",
      "09/30/2016  05:13 PM           307,936 Alia's MMR & Meningitis.jpeg\n",
      "09/30/2016  05:07 PM           216,437 Alia's MMR Vaccination.jpeg\n",
      "01/25/2018  09:57 AM                20 aliatweets.rds\n",
      "10/02/2019  08:26 PM    <DIR>          Alternate Realities\n",
      "12/12/2019  01:07 PM         1,187,560 amp_data.ipynb\n",
      "04/05/2019  11:13 PM            37,722 answers.txt\n",
      "12/10/2019  11:26 PM    <DIR>          Audacity\n",
      "04/26/2018  11:26 AM    <DIR>          Botball UAE\n",
      "12/10/2019  02:08 PM    <DIR>          capstone\n",
      "12/12/2019  01:54 AM             3,601 channels_max.txt\n",
      "06/23/2016  01:36 AM           172,544 CLASS OF 2017 IA CALENDAR.doc\n",
      "11/17/2019  12:09 PM           677,420 classaudio.wav\n",
      "09/30/2019  10:08 PM    <DIR>          College\n",
      "09/14/2017  02:56 PM    <DIR>          Computer Programming for Engineers\n",
      "12/16/2016  01:23 AM    <DIR>          Creativity & Innovation\n",
      "10/06/2018  11:20 PM    <DIR>          CSO\n",
      "11/14/2017  12:14 AM    <DIR>          Custom Office Templates\n",
      "12/14/2017  11:19 PM                 0 dark energy.enl\n",
      "06/22/2017  09:16 AM           132,701 data analysis.jpg\n",
      "11/04/2019  03:20 PM    <DIR>          Downloads\n",
      "08/06/2016  02:22 PM    <DIR>          DPC\n",
      "12/06/2019  06:48 PM    <DIR>          EKC\n",
      "08/06/2016  02:31 PM    <DIR>          Family\n",
      "06/06/2016  02:40 PM    <DIR>          Fax\n",
      "04/24/2017  01:10 AM            39,993 FEEDBACK DOC - Alia.docx\n",
      "08/16/2017  03:14 AM    <DIR>          FeedbackHub\n",
      "01/23/2018  03:29 PM    <DIR>          Formtec\n",
      "08/26/2016  04:07 AM    <DIR>          HIAMUN '16\n",
      "08/06/2016  02:33 PM    <DIR>          IB LIFE\n",
      "04/05/2019  11:04 PM             4,937 identify-language.py\n",
      "12/12/2019  01:54 AM             5,175 index_max.txt\n",
      "11/06/2019  11:18 AM    <DIR>          lab3_Alia_Chunxiao_Iva'n\n",
      "09/14/2019  02:10 PM         4,962,853 Lean Product Playbook.pdf\n",
      "11/09/2019  10:04 PM               410 luisa_pitches2.txt\n",
      "01/19/2018  06:21 PM           595,231 maloneytweets.Rda\n",
      "01/19/2018  06:21 PM                20 maloneytweets.rds\n",
      "07/17/2017  08:10 PM    <DIR>          MAVERICK YOUTH\n",
      "09/17/2019  03:51 PM    <DIR>          Max 8\n",
      "07/05/2017  02:49 PM    <DIR>          maya\n",
      "04/09/2018  01:31 AM            16,696 McKinsey_Cover_Letter.docx\n",
      "04/09/2018  01:31 AM           104,368 McKinsey_Cover_Letter.pdf\n",
      "11/18/2019  11:33 AM             2,766 MIR_Trial.ipynb\n",
      "01/27/2017  04:35 PM    <DIR>          My EndNote Library.Data\n",
      "01/27/2017  04:35 PM                 0 My EndNote Library.enl\n",
      "09/23/2019  06:59 PM    <DIR>          My Kindle Content\n",
      "12/12/2019  01:07 PM               712 new_pitches.txt\n",
      "12/08/2019  11:14 AM           129,955 newteets.csv\n",
      "01/19/2018  01:34 AM            28,142 oauth_token.Rdata\n",
      "06/24/2017  09:35 PM    <DIR>          O-MUN\n",
      "11/12/2016  01:04 PM           243,853 O-MUN on QLC.docx\n",
      "02/12/2017  04:57 PM    <DIR>          OneNote Notebooks\n",
      "05/13/2019  01:40 PM    <DIR>          Painter Essentials 6 Recovered Files\n",
      "12/12/2019  01:07 PM             1,483 pitch_max.txt\n",
      "12/12/2019  01:07 PM                 0 pitch_max_2.txt\n",
      "09/30/2019  10:01 PM    <DIR>          Politics of Code\n",
      "12/09/2019  10:28 PM    <DIR>          politics-bias-model\n",
      "11/15/2019  05:47 PM    <DIR>          project4-master\n",
      "12/11/2019  10:15 PM                 0 pymel.log\n",
      "02/13/2017  11:10 AM    <DIR>          Python Scripts\n",
      "09/30/2016  01:10 AM    <DIR>          QLC 16\n",
      "03/17/2019  03:34 PM    <DIR>          R\n",
      "12/11/2019  07:52 PM           178,834 sa_tweets.csv\n",
      "12/12/2019  03:32 AM             1,598 sa_users.csv\n",
      "12/12/2019  10:24 AM         1,001,428 saudi-bots.ipynb\n",
      "12/16/2016  01:08 AM            15,945 SAVEALEPPO.docx\n",
      "10/21/2017  09:38 PM           232,897 Scan0001.pdf\n",
      "10/21/2017  09:39 PM           228,172 Scan0002.pdf\n",
      "06/25/2017  11:16 PM    <DIR>          Scanned Documents\n",
      "12/28/2015  01:13 AM            11,674 serial number.docx\n",
      "09/07/2017  03:19 PM                26 server.js\n",
      "11/12/2018  10:44 PM    <DIR>          Sound recordings\n",
      "10/22/2017  12:01 AM            17,035 Spermatogenesis vs oogenesis.docx\n",
      "04/05/2019  06:01 PM               171 test.pred\n",
      "11/14/2016  10:31 PM               420 This PC - Shortcut.lnk\n",
      "12/09/2018  04:20 AM         2,607,247 tweets.csv\n",
      "12/08/2019  11:15 AM           129,955 tweets_3years.csv\n",
      "12/08/2019  07:09 PM           150,674 tweets_4years.csv\n",
      "12/10/2019  02:49 AM           259,507 tweets_by_month.csv\n",
      "12/12/2019  01:22 AM               392 tweets_by_volume.csv\n",
      "12/12/2019  01:34 AM            22,075 tweets_max.csv\n",
      "12/08/2019  12:28 AM    <DIR>          tweets2\n",
      "12/08/2019  12:28 AM       271,879,137 tweets2.zip\n",
      "12/10/2019  03:23 AM    <DIR>          twitter_sonification\n",
      "06/20/2017  01:31 AM    <DIR>          Unreal Projects\n",
      "02/16/2017  03:31 PM             1,790 Untitled.ipynb\n",
      "02/16/2017  03:31 PM                72 Untitled1.ipynb\n",
      "02/16/2017  05:12 PM            42,675 Untitled2.ipynb\n",
      "02/20/2017  05:52 PM               581 Untitled3.ipynb\n",
      "03/07/2017  05:16 PM             1,157 Untitled4.ipynb\n",
      "09/24/2019  12:26 AM             2,037 Untitled5.ipynb\n",
      "09/30/2019  12:28 AM             6,175 Untitled6.ipynb\n",
      "11/17/2019  12:27 PM                72 Untitled7.ipynb\n",
      "12/12/2019  03:24 AM            17,903 Untitled8.ipynb\n",
      "11/21/2016  02:23 PM            12,386 Usability Test, Japan (by Alia).xlsx\n",
      "02/26/2018  03:51 PM    <DIR>          USB\n",
      "09/13/2017  05:00 PM            36,601 VirtualDental.cpp\n",
      "09/13/2017  04:59 PM            36,601 VirtualDental.css\n",
      "09/29/2018  07:22 AM    <DIR>          Visual Studio 2017\n",
      "05/16/2019  03:33 PM    <DIR>          With & For Girls\n",
      "05/16/2019  03:10 PM    <DIR>          writing\n",
      "12/20/2016  01:23 PM            14,602 WSA Bio (Edited).docx\n",
      "12/20/2016  01:40 AM            14,550 WSA Bio.docx\n",
      "03/02/2016  09:57 PM            18,548 WSYA Application (Final Copy).docx\n",
      "06/23/2017  05:35 PM    <DIR>          xgen\n",
      "03/09/2017  04:42 PM             2,708 YoussefAzzamErrorPython.ipynb\n",
      "09/26/2019  08:22 PM    <DIR>          Zoom\n",
      "              73 File(s)    287,116,189 bytes\n",
      "              51 Dir(s)   2,001,747,968 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'newdata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-182-b44b417711fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'newdata.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3227\u001b[0m         )\n\u001b[1;32m-> 3228\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             )\n\u001b[0;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'newdata.csv'"
     ]
    }
   ],
   "source": [
    "newdata.to_csv(r'newdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  index  pitch  channels  year  month months_text  track\n",
      "0             0      1     60         1  2011      2    february      1\n",
      "1             1      1     60         1  2011      2    february      0\n",
      "2             2      1     62         1  2011      2    february      0\n",
      "3             3      1     69         1  2011      2    february      0\n",
      "4             4      1     60         1  2011      2    february      0\n",
      "..          ...    ...    ...       ...   ...    ...         ...    ...\n",
      "230         230     47     37         1  2014     12    december      0\n",
      "231         231     47     40         1  2014     12    december      0\n",
      "232         232     47     40         1  2014     12    december      0\n",
      "233         233     47     40         1  2014     12    december      0\n",
      "234         234     47     40         1  2014     12    december      0\n",
      "\n",
      "[235 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "newdata2 = pd.read_csv('newdata2.csv', encoding='latin1')  #nrows 'in_reply_to_status_id'\n",
    "print(newdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = open(\"new_tracks.txt\", \"w\")\n",
    "n = tracks.write(csv_to_text(newdata2,'track'))\n",
    "tracks.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
